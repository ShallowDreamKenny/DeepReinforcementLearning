{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gym, torch, numpy as np, torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tianshou as ts\n",
    "\n",
    "task = 'MountainCar-v0'\n",
    "lr, epoch, batch_size = 1e-5, 10, 64\n",
    "train_num, test_num = 10, 100\n",
    "gamma, n_step, target_freq = 0.9, 3, 320\n",
    "buffer_size = 20000\n",
    "eps_train, eps_test = 0.1, 0.05\n",
    "step_per_epoch, step_per_collect = 50000, 10\n",
    "logger = ts.utils.TensorboardLogger(SummaryWriter('log/dqn'))  # TensorBoard is supported!\n",
    "# For other loggers: https://tianshou.readthedocs.io/en/master/tutorials/logger.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# you can also try with SubprocVectorEnv\n",
    "train_envs = ts.env.DummyVectorEnv([lambda: gym.make(task) for _ in range(train_num)])\n",
    "test_envs = ts.env.DummyVectorEnv([lambda: gym.make(task) for _ in range(test_num)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<tianshou.env.venvs.DummyVectorEnv at 0x23f369cf130>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tianshou.utils.net.common import Net\n",
    "# you can define other net by following the API:\n",
    "# https://tianshou.readthedocs.io/en/master/tutorials/dqn.html#build-the-network\n",
    "env = gym.make(task)\n",
    "state_shape = env.observation_space.shape or env.observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "net = Net(state_shape=state_shape, action_shape=action_shape, hidden_sizes=[128, 128, 128])\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "policy = ts.policy.DQNPolicy(net, optim, gamma, n_step, target_update_freq=target_freq)\n",
    "train_collector = ts.data.Collector(policy, train_envs, ts.data.VectorReplayBuffer(buffer_size, train_num), exploration_noise=True)\n",
    "test_collector = ts.data.Collector(policy, test_envs, exploration_noise=True)  # because DQN uses epsilon-greedy method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 50001it [00:28, 1776.49it/s, env_step=50000, len=200, loss=0.000, n/ep=10, n/st=10, rew=-200.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -200.000000 ± 0.000000, best_reward: -200.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2:  57%|#####7    | 28620/50000 [00:16<00:12, 1771.78it/s, env_step=78610, len=200, loss=0.001, n/ep=0, n/st=10, rew=-200.00] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moffpolicy_trainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_collector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_collector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_per_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_per_collect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_per_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstep_per_collect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv_step\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_eps\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv_step\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_eps\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmean_rewards\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmean_rewards\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreward_threshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinished training! Use \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\trainer\\offpolicy.py:133\u001B[0m, in \u001B[0;36moffpolicy_trainer\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moffpolicy_trainer\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mstr\u001B[39m]]:  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;124;03m\"\"\"Wrapper for OffPolicyTrainer run method.\u001B[39;00m\n\u001B[0;32m    128\u001B[0m \n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03m    It is identical to ``OffpolicyTrainer(...).run()``.\u001B[39;00m\n\u001B[0;32m    130\u001B[0m \n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    :return: See :func:`~tianshou.trainer.gather_info`.\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mOffpolicyTrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\trainer\\base.py:440\u001B[0m, in \u001B[0;36mBaseTrainer.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_run \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 440\u001B[0m     \u001B[43mdeque\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxlen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# feed the entire iterator into a zero-length deque\u001B[39;00m\n\u001B[0;32m    441\u001B[0m     info \u001B[38;5;241m=\u001B[39m gather_info(\n\u001B[0;32m    442\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_time, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_collector, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_collector,\n\u001B[0;32m    443\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_reward, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_reward_std\n\u001B[0;32m    444\u001B[0m     )\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\trainer\\base.py:299\u001B[0m, in \u001B[0;36mBaseTrainer.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    296\u001B[0m         result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn/st\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_step)\n\u001B[0;32m    297\u001B[0m         t\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[1;32m--> 299\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy_update_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    300\u001B[0m     t\u001B[38;5;241m.\u001B[39mset_postfix(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_fn_flag:\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\trainer\\offpolicy.py:122\u001B[0m, in \u001B[0;36mOffpolicyTrainer.policy_update_fn\u001B[1;34m(self, data, result)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mround\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_per_step \u001B[38;5;241m*\u001B[39m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn/st\u001B[39m\u001B[38;5;124m\"\u001B[39m])):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 122\u001B[0m     losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_collector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_update_data(data, losses)\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\base.py:276\u001B[0m, in \u001B[0;36mBasePolicy.update\u001B[1;34m(self, sample_size, buffer, **kwargs)\u001B[0m\n\u001B[0;32m    274\u001B[0m batch, indices \u001B[38;5;241m=\u001B[39m buffer\u001B[38;5;241m.\u001B[39msample(sample_size)\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 276\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    277\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearn(batch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_process_fn(batch, buffer, indices)\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\modelfree\\dqn.py:106\u001B[0m, in \u001B[0;36mDQNPolicy.process_fn\u001B[1;34m(self, batch, buffer, indices)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_fn\u001B[39m(\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28mself\u001B[39m, batch: Batch, buffer: ReplayBuffer, indices: np\u001B[38;5;241m.\u001B[39mndarray\n\u001B[0;32m    100\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Batch:\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the n-step return for Q-learning targets.\u001B[39;00m\n\u001B[0;32m    102\u001B[0m \n\u001B[0;32m    103\u001B[0m \u001B[38;5;124;03m    More details can be found at\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;124;03m    :meth:`~tianshou.policy.BasePolicy.compute_nstep_return`.\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 106\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_nstep_return\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_target_q\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_n_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rew_norm\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m batch\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\base.py:391\u001B[0m, in \u001B[0;36mBasePolicy.compute_nstep_return\u001B[1;34m(batch, buffer, indice, target_q_fn, gamma, n_step, rew_norm)\u001B[0m\n\u001B[0;32m    389\u001B[0m terminal \u001B[38;5;241m=\u001B[39m indices[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 391\u001B[0m     target_q_torch \u001B[38;5;241m=\u001B[39m \u001B[43mtarget_q_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mterminal\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (bsz, ?)\u001B[39;00m\n\u001B[0;32m    392\u001B[0m target_q \u001B[38;5;241m=\u001B[39m to_numpy(target_q_torch\u001B[38;5;241m.\u001B[39mreshape(bsz, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    393\u001B[0m target_q \u001B[38;5;241m=\u001B[39m target_q \u001B[38;5;241m*\u001B[39m BasePolicy\u001B[38;5;241m.\u001B[39mvalue_mask(buffer, terminal)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\modelfree\\dqn.py:87\u001B[0m, in \u001B[0;36mDQNPolicy._target_q\u001B[1;34m(self, buffer, indices)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_target_q\u001B[39m(\u001B[38;5;28mself\u001B[39m, buffer: ReplayBuffer, indices: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m     86\u001B[0m     batch \u001B[38;5;241m=\u001B[39m buffer[indices]  \u001B[38;5;66;03m# batch.obs_next: s_{t+n}\u001B[39;00m\n\u001B[1;32m---> 87\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mobs_next\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_target:\n\u001B[0;32m     89\u001B[0m         \u001B[38;5;66;03m# target_Q = Q_old(s_, argmax(Q_new(s_, *)))\u001B[39;00m\n\u001B[0;32m     90\u001B[0m         target_q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(batch, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_old\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobs_next\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mlogits\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\modelfree\\dqn.py:160\u001B[0m, in \u001B[0;36mDQNPolicy.forward\u001B[1;34m(self, batch, state, model, input, **kwargs)\u001B[0m\n\u001B[0;32m    158\u001B[0m obs \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;28minput\u001B[39m]\n\u001B[0;32m    159\u001B[0m obs_next \u001B[38;5;241m=\u001B[39m obs\u001B[38;5;241m.\u001B[39mobs \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(obs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobs\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m obs\n\u001B[1;32m--> 160\u001B[0m logits, hidden \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs_next\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_q_value(logits, \u001B[38;5;28mgetattr\u001B[39m(obs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_action_num\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\utils\\net\\common.py:210\u001B[0m, in \u001B[0;36mNet.forward\u001B[1;34m(self, obs, state, info)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    205\u001B[0m     obs: Union[np\u001B[38;5;241m.\u001B[39mndarray, torch\u001B[38;5;241m.\u001B[39mTensor],\n\u001B[0;32m    206\u001B[0m     state: Any \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    207\u001B[0m     info: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {},\n\u001B[0;32m    208\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, Any]:\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;124;03m\"\"\"Mapping: obs -> flatten (inside MLP)-> logits.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 210\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    211\u001B[0m     bsz \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    212\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_dueling:  \u001B[38;5;66;03m# Dueling DQN\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\utils\\net\\common.py:109\u001B[0m, in \u001B[0;36mMLP.forward\u001B[1;34m(self, obs)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflatten_input:\n\u001B[0;32m    108\u001B[0m     obs \u001B[38;5;241m=\u001B[39m obs\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 109\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\RL\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "result = ts.trainer.offpolicy_trainer(\n",
    "    policy, train_collector, test_collector, epoch, step_per_epoch, step_per_collect,\n",
    "    test_num, batch_size, update_per_step=1 / step_per_collect,\n",
    "    train_fn=lambda epoch, env_step: policy.set_eps(eps_train),\n",
    "    test_fn=lambda epoch, env_step: policy.set_eps(eps_test),\n",
    "    stop_fn=lambda mean_rewards: mean_rewards >= env.spec.reward_threshold,\n",
    "    logger=logger)\n",
    "print(f'Finished training! Use {result[\"duration\"]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(policy.state_dict(), 'dqn.pth')\n",
    "policy.load_state_dict(torch.load('dqn.pth'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenny\\.conda\\envs\\RL\\lib\\site-packages\\tianshou\\data\\collector.py:68: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'n/ep': 1,\n 'n/st': 200,\n 'rews': array([-200.]),\n 'lens': array([200]),\n 'idxs': array([0]),\n 'rew': -200.0,\n 'len': 200.0,\n 'rew_std': 0.0,\n 'len_std': 0.0}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(task, render_mode=\"human\")\n",
    "policy.eval()\n",
    "policy.set_eps(eps_test)\n",
    "collector = ts.data.Collector(policy, env, exploration_noise=True)\n",
    "collector.collect(n_episode=1, render=1 / 35)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
